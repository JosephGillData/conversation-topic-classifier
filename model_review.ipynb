{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Model Output Analysis: Conversation Topic Classifier\n",
    "\n",
    "Comprehensive analysis of AI classification outputs including topic labels, operational metadata, and cross-field correlations.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Setup & Data Loading** - Import libraries, load dataset, categorical overview\n",
    "2. **Gold Set Evaluation** - Compare against manual labels\n",
    "3. **Topic Distribution Analysis** - Classification patterns\n",
    "4. **Confidence Analysis** - Model certainty patterns\n",
    "5. **Emotion Analysis** - Customer emotional state patterns\n",
    "6. **Difficulty Analysis** - Resolution difficulty patterns\n",
    "7. **Risk & Escalation Analysis** - Risk levels and escalation triggers\n",
    "8. **Operational Actions Analysis** - Recommended actions patterns\n",
    "9. **Root Cause Analysis** - Root cause code patterns\n",
    "10. **Cross-Field Correlations** - Relationships between categorical fields\n",
    "11. **Handler Actionability** - Summary quality analysis\n",
    "12. **Model Health Dashboard** - Summary metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import required libraries for data analysis and visualization.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import ast\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Chart export settings\n",
    "EXPORT_CHARTS = False\n",
    "CHART_DPI = 150\n",
    "\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the model output dataset.\n",
    "\"\"\"\n",
    "AI_LABELS_PATH = \"data/conversations_ai_classified.csv\"\n",
    "MANUAL_LABELS_PATH = 'data/conversations_ai_classified_gpt5_2_simple.csv'\n",
    "\n",
    "df = pd.read_csv(AI_LABELS_PATH)\n",
    "\n",
    "# Parse list columns\n",
    "def safe_parse_list(val):\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df['operational_actions'] = df['operational_actions'].apply(safe_parse_list)\n",
    "df['escalation_flags'] = df['escalation_flags'].apply(safe_parse_list)\n",
    "\n",
    "print(f\"Loaded {len(df)} conversations\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "categorical-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overview of all categorical columns in the dataset.\n",
    "\"\"\"\n",
    "categorical_cols = ['topic', 'confidence', 'emotion', 'difficulty', 'risk_level', \n",
    "                    'escalation_required', 'root_cause_code']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CATEGORICAL COLUMNS OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Values: {df[col].unique().tolist()[:10]}\")\n",
    "    \n",
    "# List columns\n",
    "print(f\"\\nOPERATIONAL_ACTIONS (list column):\")\n",
    "all_actions = [a for actions in df['operational_actions'] for a in actions]\n",
    "print(f\"  Unique actions: {len(set(all_actions))}\")\n",
    "print(f\"  Total occurrences: {len(all_actions)}\")\n",
    "\n",
    "print(f\"\\nESCALATION_FLAGS (list column):\")\n",
    "all_flags = [f for flags in df['escalation_flags'] for f in flags]\n",
    "print(f\"  Unique flags: {len(set(all_flags))}\")\n",
    "print(f\"  Total occurrences: {len(all_flags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gold-set-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Gold Set Evaluation\n",
    "\n",
    "Compare AI classifications against manually labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-gold",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load and merge gold (manual) labels for evaluation.\n",
    "\"\"\"\n",
    "try:\n",
    "    manual_df = pd.read_csv(MANUAL_LABELS_PATH)\n",
    "    pred_df = df[['conversation_id', 'topic']].rename(columns={'topic': 'label_pred'})\n",
    "    true_df = manual_df[['conversation_id', 'topic']].rename(columns={'topic': 'label_true'})\n",
    "    eval_df = true_df.merge(pred_df, on='conversation_id', how='inner').dropna()\n",
    "    GOLD_SET_AVAILABLE = len(eval_df) > 0\n",
    "    print(f\"Gold set loaded: {len(eval_df)} conversations\")\n",
    "except Exception as e:\n",
    "    GOLD_SET_AVAILABLE = False\n",
    "    print(f\"No gold set available: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classification report comparing AI vs manual labels.\n",
    "\"\"\"\n",
    "if GOLD_SET_AVAILABLE:\n",
    "    print(\"Classification Report (AI vs Manual Labels):\")\n",
    "    print(\"=\"*70)\n",
    "    print(classification_report(eval_df['label_true'], eval_df['label_pred']))\n",
    "    accuracy = (eval_df['label_true'] == eval_df['label_pred']).mean() * 100\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.1f}%\")\n",
    "else:\n",
    "    print(\"Skipped - no gold set available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Confusion matrix visualization.\n",
    "\"\"\"\n",
    "if GOLD_SET_AVAILABLE and len(eval_df) > 0:\n",
    "    labels = sorted(set(eval_df['label_true'].unique()) | set(eval_df['label_pred'].unique()))\n",
    "    cm = confusion_matrix(eval_df['label_true'], eval_df['label_pred'], labels=labels)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    im = ax.imshow(cm, cmap='Blues')\n",
    "    \n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_yticklabels(labels, fontsize=8)\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, cm[i, j], ha='center', va='center', fontsize=8)\n",
    "    \n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_title('Confusion Matrix: AI vs Manual Labels', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Confusion matrix skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "topic-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Topic Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "topic-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Topic distribution statistics.\n",
    "\"\"\"\n",
    "topic_counts = df['topic'].value_counts()\n",
    "topic_pcts = df['topic'].value_counts(normalize=True) * 100\n",
    "\n",
    "topic_dist = pd.DataFrame({\n",
    "    'Count': topic_counts,\n",
    "    'Percentage': topic_pcts.round(1)\n",
    "})\n",
    "\n",
    "print(f\"Total topics: {len(topic_counts)}\")\n",
    "print(f\"\\nTopic Distribution:\")\n",
    "topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "topic-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Topic distribution bar chart.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "topic_counts_sorted = topic_counts.sort_values(ascending=True)\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(topic_counts)))\n",
    "bars = ax.barh(topic_counts_sorted.index, topic_counts_sorted.values, color=colors)\n",
    "\n",
    "for bar, count in zip(bars, topic_counts_sorted.values):\n",
    "    ax.text(bar.get_width() + 5, bar.get_y() + bar.get_height()/2, \n",
    "            f'{count} ({count/len(df)*100:.1f}%)', va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Number of Conversations')\n",
    "ax.set_title('Topic Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(topic_counts_sorted.values) * 1.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidence-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidence-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overall confidence distribution.\n",
    "\"\"\"\n",
    "conf_counts = df['confidence'].value_counts().reindex(['high', 'medium', 'low']).fillna(0).astype(int)\n",
    "conf_pcts = (conf_counts / len(df) * 100).round(1)\n",
    "\n",
    "print(\"Overall Confidence Distribution:\")\n",
    "pd.DataFrame({'Count': conf_counts, 'Percentage': conf_pcts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidence-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Confidence by topic heatmap.\n",
    "\"\"\"\n",
    "conf_by_topic = pd.crosstab(df['topic'], df['confidence'], normalize='index') * 100\n",
    "for col in ['high', 'medium', 'low']:\n",
    "    if col not in conf_by_topic.columns:\n",
    "        conf_by_topic[col] = 0\n",
    "conf_by_topic = conf_by_topic[['high', 'medium', 'low']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(conf_by_topic.values, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "\n",
    "ax.set_xticks(range(len(conf_by_topic.columns)))\n",
    "ax.set_yticks(range(len(conf_by_topic.index)))\n",
    "ax.set_xticklabels(conf_by_topic.columns)\n",
    "ax.set_yticklabels(conf_by_topic.index, fontsize=8)\n",
    "\n",
    "for i in range(len(conf_by_topic.index)):\n",
    "    for j in range(len(conf_by_topic.columns)):\n",
    "        val = conf_by_topic.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=9)\n",
    "\n",
    "ax.set_title('Confidence by Topic (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotion-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Emotion Analysis\n",
    "\n",
    "Analyzing customer emotional states to understand sentiment patterns across topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overall emotion distribution.\n",
    "\"\"\"\n",
    "emotion_counts = df['emotion'].value_counts()\n",
    "emotion_pcts = df['emotion'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Emotion Distribution:\")\n",
    "emotion_dist = pd.DataFrame({\n",
    "    'Count': emotion_counts,\n",
    "    'Percentage': emotion_pcts.round(1)\n",
    "})\n",
    "emotion_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Emotion distribution bar chart with color coding.\n",
    "\"\"\"\n",
    "emotion_colors = {\n",
    "    'calm': '#2ecc71',\n",
    "    'confused': '#f39c12',\n",
    "    'frustrated': '#e67e22',\n",
    "    'angry': '#e74c3c',\n",
    "    'anxious': '#9b59b6',\n",
    "    'urgent': '#c0392b'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "emotions = emotion_counts.index.tolist()\n",
    "colors = [emotion_colors.get(e, '#95a5a6') for e in emotions]\n",
    "\n",
    "bars = ax.bar(emotions, emotion_counts.values, color=colors)\n",
    "\n",
    "for bar, count, pct in zip(bars, emotion_counts.values, emotion_pcts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "            f'{count}\\n({pct:.1f}%)', ha='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Customer Emotion Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(emotion_counts.values) * 1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Emotion by Topic heatmap.\n",
    "\"\"\"\n",
    "emotion_by_topic = pd.crosstab(df['topic'], df['emotion'], normalize='index') * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(emotion_by_topic.values, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(emotion_by_topic.columns)))\n",
    "ax.set_yticks(range(len(emotion_by_topic.index)))\n",
    "ax.set_xticklabels(emotion_by_topic.columns, rotation=45, ha='right')\n",
    "ax.set_yticklabels(emotion_by_topic.index, fontsize=8)\n",
    "\n",
    "for i in range(len(emotion_by_topic.index)):\n",
    "    for j in range(len(emotion_by_topic.columns)):\n",
    "        val = emotion_by_topic.iloc[i, j]\n",
    "        if val > 0:\n",
    "            ax.text(j, i, f'{val:.0f}', ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax.set_title('Emotion Distribution by Topic (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEmotion by Topic (counts):\")\n",
    "pd.crosstab(df['topic'], df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Emotion intensity score by topic.\n",
    "Scale: calm=0, confused=1, anxious=2, frustrated=3, angry=4, urgent=5\n",
    "\"\"\"\n",
    "emotion_intensity = {\n",
    "    'calm': 0, 'confused': 1, 'anxious': 2, \n",
    "    'frustrated': 3, 'angry': 4, 'urgent': 5\n",
    "}\n",
    "\n",
    "df['emotion_score'] = df['emotion'].map(emotion_intensity)\n",
    "\n",
    "intensity_by_topic = df.groupby('topic')['emotion_score'].agg(['mean', 'std', 'count'])\n",
    "intensity_by_topic = intensity_by_topic.sort_values('mean', ascending=False)\n",
    "intensity_by_topic.columns = ['Avg Intensity', 'Std Dev', 'Count']\n",
    "\n",
    "print(\"Emotion Intensity by Topic (0=calm to 5=urgent):\")\n",
    "intensity_by_topic.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-intensity-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Emotion intensity bar chart.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "intensity_sorted = intensity_by_topic['Avg Intensity'].sort_values(ascending=True)\n",
    "colors = plt.cm.RdYlGn_r(intensity_sorted.values / 5)\n",
    "\n",
    "bars = ax.barh(intensity_sorted.index, intensity_sorted.values, color=colors)\n",
    "\n",
    "for bar, val in zip(bars, intensity_sorted.values):\n",
    "    ax.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.2f}', va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Average Emotion Intensity (0=calm, 5=urgent)')\n",
    "ax.set_title('Emotion Intensity by Topic', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 5.5)\n",
    "ax.axvline(x=intensity_by_topic['Avg Intensity'].mean(), color='red', linestyle='--', \n",
    "           label=f'Avg: {intensity_by_topic[\"Avg Intensity\"].mean():.2f}')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficulty-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Difficulty Analysis\n",
    "\n",
    "Analyzing resolution difficulty across topics and other dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficulty-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overall difficulty distribution.\n",
    "\"\"\"\n",
    "diff_counts = df['difficulty'].value_counts().reindex(['low', 'medium', 'high']).fillna(0).astype(int)\n",
    "diff_pcts = (diff_counts / len(df) * 100).round(1)\n",
    "\n",
    "print(\"Difficulty Distribution:\")\n",
    "pd.DataFrame({'Count': diff_counts, 'Percentage': diff_pcts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficulty-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Difficulty distribution bar chart.\n",
    "\"\"\"\n",
    "diff_colors = {'low': '#2ecc71', 'medium': '#f39c12', 'high': '#e74c3c'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(diff_counts.index, diff_counts.values, \n",
    "              color=[diff_colors.get(d, 'gray') for d in diff_counts.index])\n",
    "\n",
    "for bar, count, pct in zip(bars, diff_counts.values, diff_pcts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "            f'{count}\\n({pct}%)', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Difficulty Level')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Resolution Difficulty Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(diff_counts.values) * 1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficulty-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Difficulty by Topic heatmap.\n",
    "\"\"\"\n",
    "diff_by_topic = pd.crosstab(df['topic'], df['difficulty'], normalize='index') * 100\n",
    "for col in ['low', 'medium', 'high']:\n",
    "    if col not in diff_by_topic.columns:\n",
    "        diff_by_topic[col] = 0\n",
    "diff_by_topic = diff_by_topic[['low', 'medium', 'high']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(diff_by_topic.values, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=100)\n",
    "\n",
    "ax.set_xticks(range(len(diff_by_topic.columns)))\n",
    "ax.set_yticks(range(len(diff_by_topic.index)))\n",
    "ax.set_xticklabels(diff_by_topic.columns)\n",
    "ax.set_yticklabels(diff_by_topic.index, fontsize=8)\n",
    "\n",
    "for i in range(len(diff_by_topic.index)):\n",
    "    for j in range(len(diff_by_topic.columns)):\n",
    "        val = diff_by_topic.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=9)\n",
    "\n",
    "ax.set_title('Difficulty by Topic (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDifficulty by Topic (counts):\")\n",
    "pd.crosstab(df['topic'], df['difficulty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficulty-by-emotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Difficulty by Emotion heatmap - understanding correlation.\n",
    "\"\"\"\n",
    "diff_by_emotion = pd.crosstab(df['difficulty'], df['emotion'], normalize='index') * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(diff_by_emotion.values, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(diff_by_emotion.columns)))\n",
    "ax.set_yticks(range(len(diff_by_emotion.index)))\n",
    "ax.set_xticklabels(diff_by_emotion.columns, rotation=45, ha='right')\n",
    "ax.set_yticklabels(diff_by_emotion.index)\n",
    "\n",
    "for i in range(len(diff_by_emotion.index)):\n",
    "    for j in range(len(diff_by_emotion.columns)):\n",
    "        val = diff_by_emotion.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Difficulty')\n",
    "ax.set_title('Emotion Distribution by Difficulty Level (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDifficulty by Emotion (counts):\")\n",
    "pd.crosstab(df['difficulty'], df['emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "risk-escalation-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Risk & Escalation Analysis\n",
    "\n",
    "Analyzing risk levels, escalation requirements, and escalation triggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "risk-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Risk level distribution.\n",
    "\"\"\"\n",
    "risk_counts = df['risk_level'].value_counts().reindex(['none', 'low', 'medium', 'high']).fillna(0).astype(int)\n",
    "risk_pcts = (risk_counts / len(df) * 100).round(1)\n",
    "\n",
    "print(\"Risk Level Distribution:\")\n",
    "pd.DataFrame({'Count': risk_counts, 'Percentage': risk_pcts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "risk-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Risk level bar chart.\n",
    "\"\"\"\n",
    "risk_colors = {'none': '#95a5a6', 'low': '#2ecc71', 'medium': '#f39c12', 'high': '#e74c3c'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(risk_counts.index, risk_counts.values, \n",
    "              color=[risk_colors.get(r, 'gray') for r in risk_counts.index])\n",
    "\n",
    "for bar, count, pct in zip(bars, risk_counts.values, risk_pcts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "            f'{count}\\n({pct}%)', ha='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Risk Level')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Risk Level Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(risk_counts.values) * 1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "risk-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Risk level by topic heatmap.\n",
    "\"\"\"\n",
    "risk_by_topic = pd.crosstab(df['topic'], df['risk_level'], normalize='index') * 100\n",
    "for col in ['none', 'low', 'medium', 'high']:\n",
    "    if col not in risk_by_topic.columns:\n",
    "        risk_by_topic[col] = 0\n",
    "risk_by_topic = risk_by_topic[['none', 'low', 'medium', 'high']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(risk_by_topic.values, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=100)\n",
    "\n",
    "ax.set_xticks(range(len(risk_by_topic.columns)))\n",
    "ax.set_yticks(range(len(risk_by_topic.index)))\n",
    "ax.set_xticklabels(risk_by_topic.columns)\n",
    "ax.set_yticklabels(risk_by_topic.index, fontsize=8)\n",
    "\n",
    "for i in range(len(risk_by_topic.index)):\n",
    "    for j in range(len(risk_by_topic.columns)):\n",
    "        val = risk_by_topic.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=9)\n",
    "\n",
    "ax.set_title('Risk Level by Topic (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "risk-by-emotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Risk level by emotion.\n",
    "\"\"\"\n",
    "risk_by_emotion = pd.crosstab(df['risk_level'], df['emotion'], normalize='index') * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(risk_by_emotion.values, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(risk_by_emotion.columns)))\n",
    "ax.set_yticks(range(len(risk_by_emotion.index)))\n",
    "ax.set_xticklabels(risk_by_emotion.columns, rotation=45, ha='right')\n",
    "ax.set_yticklabels(risk_by_emotion.index)\n",
    "\n",
    "for i in range(len(risk_by_emotion.index)):\n",
    "    for j in range(len(risk_by_emotion.columns)):\n",
    "        val = risk_by_emotion.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Risk Level')\n",
    "ax.set_title('Emotion Distribution by Risk Level (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Escalation required distribution.\n",
    "\"\"\"\n",
    "esc_counts = df['escalation_required'].value_counts()\n",
    "esc_pcts = df['escalation_required'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Escalation Required Distribution:\")\n",
    "pd.DataFrame({'Count': esc_counts, 'Percentage': esc_pcts.round(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Escalation rate by topic.\n",
    "\"\"\"\n",
    "esc_by_topic = df.groupby('topic')['escalation_required'].agg(['sum', 'count'])\n",
    "esc_by_topic['rate'] = (esc_by_topic['sum'] / esc_by_topic['count'] * 100).round(1)\n",
    "esc_by_topic = esc_by_topic.sort_values('rate', ascending=False)\n",
    "esc_by_topic.columns = ['Escalations', 'Total', 'Rate (%)']\n",
    "\n",
    "print(\"Escalation Rate by Topic:\")\n",
    "esc_by_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-by-emotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Escalation rate by emotion.\n",
    "\"\"\"\n",
    "esc_by_emotion = df.groupby('emotion')['escalation_required'].agg(['sum', 'count'])\n",
    "esc_by_emotion['rate'] = (esc_by_emotion['sum'] / esc_by_emotion['count'] * 100).round(1)\n",
    "esc_by_emotion = esc_by_emotion.sort_values('rate', ascending=False)\n",
    "esc_by_emotion.columns = ['Escalations', 'Total', 'Rate (%)']\n",
    "\n",
    "print(\"Escalation Rate by Emotion:\")\n",
    "esc_by_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-flags-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Escalation flags distribution.\n",
    "\"\"\"\n",
    "all_flags = [f for flags in df['escalation_flags'] for f in flags]\n",
    "flag_counts = Counter(all_flags)\n",
    "\n",
    "if flag_counts:\n",
    "    flag_df = pd.DataFrame.from_dict(flag_counts, orient='index', columns=['Count'])\n",
    "    flag_df = flag_df.sort_values('Count', ascending=False)\n",
    "    flag_df['Percentage'] = (flag_df['Count'] / len(df) * 100).round(1)\n",
    "    \n",
    "    print(f\"Escalation Flags Distribution (conversations with any flag: {sum(len(f) > 0 for f in df['escalation_flags'])}):\")\n",
    "    display(flag_df)\n",
    "    \n",
    "    # Bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    bars = ax.barh(flag_df.index, flag_df['Count'].values, color='#e74c3c')\n",
    "    \n",
    "    for bar, count in zip(bars, flag_df['Count'].values):\n",
    "        ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                str(count), va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_title('Escalation Flags Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No escalation flags found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-flags-cooccurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Escalation flags co-occurrence analysis.\n",
    "\"\"\"\n",
    "multi_flag_convos = df[df['escalation_flags'].apply(len) > 1]\n",
    "\n",
    "if len(multi_flag_convos) > 0:\n",
    "    flag_pairs = []\n",
    "    for flags in multi_flag_convos['escalation_flags']:\n",
    "        flag_pairs.extend(combinations(sorted(flags), 2))\n",
    "    \n",
    "    if flag_pairs:\n",
    "        pair_counts = Counter(flag_pairs)\n",
    "        print(f\"Conversations with multiple flags: {len(multi_flag_convos)}\")\n",
    "        print(\"\\nMost common flag combinations:\")\n",
    "        for pair, count in pair_counts.most_common(10):\n",
    "            print(f\"  {pair[0]} + {pair[1]}: {count}\")\n",
    "    else:\n",
    "        print(\"No flag combinations found.\")\n",
    "else:\n",
    "    print(\"No conversations with multiple escalation flags.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actions-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Operational Actions Analysis\n",
    "\n",
    "Analyzing recommended operational actions across conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Operational actions distribution.\n",
    "\"\"\"\n",
    "all_actions = [a for actions in df['operational_actions'] for a in actions]\n",
    "action_counts = Counter(all_actions)\n",
    "\n",
    "action_df = pd.DataFrame.from_dict(action_counts, orient='index', columns=['Count'])\n",
    "action_df = action_df.sort_values('Count', ascending=False)\n",
    "action_df['Percentage'] = (action_df['Count'] / len(df) * 100).round(1)\n",
    "\n",
    "print(f\"Total unique actions: {len(action_counts)}\")\n",
    "print(f\"Total action occurrences: {len(all_actions)}\")\n",
    "print(f\"Avg actions per conversation: {len(all_actions)/len(df):.2f}\")\n",
    "print(f\"\\nOperational Actions Distribution:\")\n",
    "action_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Operational actions bar chart.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "action_sorted = action_df.sort_values('Count', ascending=True)\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(action_sorted)))\n",
    "\n",
    "bars = ax.barh(action_sorted.index, action_sorted['Count'].values, color=colors)\n",
    "\n",
    "for bar, count in zip(bars, action_sorted['Count'].values):\n",
    "    ax.text(bar.get_width() + 2, bar.get_y() + bar.get_height()/2, \n",
    "            str(count), va='center', fontsize=8)\n",
    "\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Operational Actions Distribution', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Top actions by topic.\n",
    "\"\"\"\n",
    "action_topic_data = []\n",
    "for _, row in df.iterrows():\n",
    "    for action in row['operational_actions']:\n",
    "        action_topic_data.append({'topic': row['topic'], 'action': action})\n",
    "\n",
    "action_topic_df = pd.DataFrame(action_topic_data)\n",
    "\n",
    "if len(action_topic_df) > 0:\n",
    "    action_by_topic = pd.crosstab(action_topic_df['action'], action_topic_df['topic'])\n",
    "    \n",
    "    # Show top 10 actions\n",
    "    top_actions = action_df.head(10).index.tolist()\n",
    "    action_by_topic_top = action_by_topic.loc[action_by_topic.index.isin(top_actions)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    im = ax.imshow(action_by_topic_top.values, cmap='YlGnBu', aspect='auto')\n",
    "    \n",
    "    ax.set_xticks(range(len(action_by_topic_top.columns)))\n",
    "    ax.set_yticks(range(len(action_by_topic_top.index)))\n",
    "    ax.set_xticklabels(action_by_topic_top.columns, rotation=45, ha='right', fontsize=7)\n",
    "    ax.set_yticklabels(action_by_topic_top.index, fontsize=8)\n",
    "    \n",
    "    for i in range(len(action_by_topic_top.index)):\n",
    "        for j in range(len(action_by_topic_top.columns)):\n",
    "            val = action_by_topic_top.iloc[i, j]\n",
    "            if val > 0:\n",
    "                ax.text(j, i, str(val), ha='center', va='center', fontsize=7)\n",
    "    \n",
    "    ax.set_title('Top 10 Operational Actions by Topic', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im, label='Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-by-emotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Actions by emotion.\n",
    "\"\"\"\n",
    "action_emotion_data = []\n",
    "for _, row in df.iterrows():\n",
    "    for action in row['operational_actions']:\n",
    "        action_emotion_data.append({'emotion': row['emotion'], 'action': action})\n",
    "\n",
    "action_emotion_df = pd.DataFrame(action_emotion_data)\n",
    "\n",
    "if len(action_emotion_df) > 0:\n",
    "    action_by_emotion = pd.crosstab(action_emotion_df['action'], action_emotion_df['emotion'])\n",
    "    \n",
    "    top_actions = action_df.head(10).index.tolist()\n",
    "    action_by_emotion_top = action_by_emotion.loc[action_by_emotion.index.isin(top_actions)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    im = ax.imshow(action_by_emotion_top.values, cmap='YlOrRd', aspect='auto')\n",
    "    \n",
    "    ax.set_xticks(range(len(action_by_emotion_top.columns)))\n",
    "    ax.set_yticks(range(len(action_by_emotion_top.index)))\n",
    "    ax.set_xticklabels(action_by_emotion_top.columns, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(action_by_emotion_top.index, fontsize=8)\n",
    "    \n",
    "    for i in range(len(action_by_emotion_top.index)):\n",
    "        for j in range(len(action_by_emotion_top.columns)):\n",
    "            val = action_by_emotion_top.iloc[i, j]\n",
    "            if val > 0:\n",
    "                ax.text(j, i, str(val), ha='center', va='center', fontsize=8)\n",
    "    \n",
    "    ax.set_title('Top 10 Actions by Emotion', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im, label='Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-by-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Actions by difficulty level.\n",
    "\"\"\"\n",
    "action_diff_data = []\n",
    "for _, row in df.iterrows():\n",
    "    for action in row['operational_actions']:\n",
    "        action_diff_data.append({'difficulty': row['difficulty'], 'action': action})\n",
    "\n",
    "action_diff_df = pd.DataFrame(action_diff_data)\n",
    "\n",
    "if len(action_diff_df) > 0:\n",
    "    action_by_diff = pd.crosstab(action_diff_df['action'], action_diff_df['difficulty'])\n",
    "    \n",
    "    # Ensure column order\n",
    "    for col in ['low', 'medium', 'high']:\n",
    "        if col not in action_by_diff.columns:\n",
    "            action_by_diff[col] = 0\n",
    "    action_by_diff = action_by_diff[['low', 'medium', 'high']]\n",
    "    \n",
    "    top_actions = action_df.head(10).index.tolist()\n",
    "    action_by_diff_top = action_by_diff.loc[action_by_diff.index.isin(top_actions)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(action_by_diff_top.values, cmap='RdYlGn_r', aspect='auto')\n",
    "    \n",
    "    ax.set_xticks(range(len(action_by_diff_top.columns)))\n",
    "    ax.set_yticks(range(len(action_by_diff_top.index)))\n",
    "    ax.set_xticklabels(action_by_diff_top.columns)\n",
    "    ax.set_yticklabels(action_by_diff_top.index, fontsize=8)\n",
    "    \n",
    "    for i in range(len(action_by_diff_top.index)):\n",
    "        for j in range(len(action_by_diff_top.columns)):\n",
    "            val = action_by_diff_top.iloc[i, j]\n",
    "            ax.text(j, i, str(val), ha='center', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_title('Top 10 Actions by Difficulty', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im, label='Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-cooccurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Action co-occurrence analysis.\n",
    "\"\"\"\n",
    "multi_action_convos = df[df['operational_actions'].apply(len) > 1]\n",
    "\n",
    "print(f\"Conversations with multiple actions: {len(multi_action_convos)} ({len(multi_action_convos)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if len(multi_action_convos) > 0:\n",
    "    action_pairs = []\n",
    "    for actions in multi_action_convos['operational_actions']:\n",
    "        action_pairs.extend(combinations(sorted(actions), 2))\n",
    "    \n",
    "    if action_pairs:\n",
    "        pair_counts = Counter(action_pairs)\n",
    "        print(\"\\nMost common action combinations:\")\n",
    "        for pair, count in pair_counts.most_common(15):\n",
    "            print(f\"  {pair[0]} + {pair[1]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "root-cause-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Root Cause Analysis\n",
    "\n",
    "Analyzing root cause codes across conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root-cause-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Root cause code distribution.\n",
    "\"\"\"\n",
    "rc_counts = df['root_cause_code'].value_counts()\n",
    "rc_pcts = df['root_cause_code'].value_counts(normalize=True) * 100\n",
    "\n",
    "rc_df = pd.DataFrame({\n",
    "    'Count': rc_counts,\n",
    "    'Percentage': rc_pcts.round(1)\n",
    "})\n",
    "\n",
    "print(f\"Total unique root cause codes: {len(rc_counts)}\")\n",
    "print(f\"\\nRoot Cause Code Distribution:\")\n",
    "rc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root-cause-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Root cause code bar chart.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "rc_sorted = rc_counts.sort_values(ascending=True)\n",
    "colors = plt.cm.Paired(np.linspace(0, 1, len(rc_sorted)))\n",
    "\n",
    "bars = ax.barh(rc_sorted.index, rc_sorted.values, color=colors)\n",
    "\n",
    "for bar, count in zip(bars, rc_sorted.values):\n",
    "    ax.text(bar.get_width() + 2, bar.get_y() + bar.get_height()/2, \n",
    "            f'{count} ({count/len(df)*100:.1f}%)', va='center', fontsize=8)\n",
    "\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Root Cause Code Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(rc_sorted.values) * 1.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root-cause-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Root cause by topic heatmap.\n",
    "\"\"\"\n",
    "rc_by_topic = pd.crosstab(df['root_cause_code'], df['topic'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "im = ax.imshow(rc_by_topic.values, cmap='YlGnBu', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(rc_by_topic.columns)))\n",
    "ax.set_yticks(range(len(rc_by_topic.index)))\n",
    "ax.set_xticklabels(rc_by_topic.columns, rotation=45, ha='right', fontsize=7)\n",
    "ax.set_yticklabels(rc_by_topic.index, fontsize=8)\n",
    "\n",
    "for i in range(len(rc_by_topic.index)):\n",
    "    for j in range(len(rc_by_topic.columns)):\n",
    "        val = rc_by_topic.iloc[i, j]\n",
    "        if val > 0:\n",
    "            ax.text(j, i, str(val), ha='center', va='center', fontsize=7)\n",
    "\n",
    "ax.set_title('Root Cause Codes by Topic', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root-cause-by-emotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Root cause by emotion.\n",
    "\"\"\"\n",
    "rc_by_emotion = pd.crosstab(df['root_cause_code'], df['emotion'])\n",
    "\n",
    "# Show top 10 root causes\n",
    "top_rc = rc_counts.head(10).index.tolist()\n",
    "rc_by_emotion_top = rc_by_emotion.loc[rc_by_emotion.index.isin(top_rc)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(rc_by_emotion_top.values, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(rc_by_emotion_top.columns)))\n",
    "ax.set_yticks(range(len(rc_by_emotion_top.index)))\n",
    "ax.set_xticklabels(rc_by_emotion_top.columns, rotation=45, ha='right')\n",
    "ax.set_yticklabels(rc_by_emotion_top.index, fontsize=8)\n",
    "\n",
    "for i in range(len(rc_by_emotion_top.index)):\n",
    "    for j in range(len(rc_by_emotion_top.columns)):\n",
    "        val = rc_by_emotion_top.iloc[i, j]\n",
    "        if val > 0:\n",
    "            ax.text(j, i, str(val), ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax.set_title('Top 10 Root Causes by Emotion', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root-cause-by-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Root cause by difficulty.\n",
    "\"\"\"\n",
    "rc_by_diff = pd.crosstab(df['root_cause_code'], df['difficulty'])\n",
    "\n",
    "for col in ['low', 'medium', 'high']:\n",
    "    if col not in rc_by_diff.columns:\n",
    "        rc_by_diff[col] = 0\n",
    "rc_by_diff = rc_by_diff[['low', 'medium', 'high']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "im = ax.imshow(rc_by_diff.values, cmap='RdYlGn_r', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(rc_by_diff.columns)))\n",
    "ax.set_yticks(range(len(rc_by_diff.index)))\n",
    "ax.set_xticklabels(rc_by_diff.columns)\n",
    "ax.set_yticklabels(rc_by_diff.index, fontsize=8)\n",
    "\n",
    "for i in range(len(rc_by_diff.index)):\n",
    "    for j in range(len(rc_by_diff.columns)):\n",
    "        val = rc_by_diff.iloc[i, j]\n",
    "        ax.text(j, i, str(val), ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax.set_title('Root Cause Codes by Difficulty', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-correlations-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Cross-Field Correlations\n",
    "\n",
    "Analyzing relationships between multiple categorical fields to identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-difficulty-escalation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Emotion x Difficulty -> Escalation Rate heatmap.\n",
    "Shows how the combination of emotion and difficulty affects escalation probability.\n",
    "\"\"\"\n",
    "# Create pivot table: escalation rate by emotion and difficulty\n",
    "emotion_diff_esc = df.pivot_table(\n",
    "    index='emotion', \n",
    "    columns='difficulty', \n",
    "    values='escalation_required', \n",
    "    aggfunc='mean'\n",
    ") * 100\n",
    "\n",
    "# Reorder columns\n",
    "for col in ['low', 'medium', 'high']:\n",
    "    if col not in emotion_diff_esc.columns:\n",
    "        emotion_diff_esc[col] = 0\n",
    "emotion_diff_esc = emotion_diff_esc[['low', 'medium', 'high']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(emotion_diff_esc.values, cmap='RdYlGn_r', aspect='auto', vmin=0)\n",
    "\n",
    "ax.set_xticks(range(len(emotion_diff_esc.columns)))\n",
    "ax.set_yticks(range(len(emotion_diff_esc.index)))\n",
    "ax.set_xticklabels(emotion_diff_esc.columns)\n",
    "ax.set_yticklabels(emotion_diff_esc.index)\n",
    "\n",
    "for i in range(len(emotion_diff_esc.index)):\n",
    "    for j in range(len(emotion_diff_esc.columns)):\n",
    "        val = emotion_diff_esc.iloc[i, j]\n",
    "        if not pd.isna(val):\n",
    "            ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Difficulty')\n",
    "ax.set_ylabel('Emotion')\n",
    "ax.set_title('Escalation Rate by Emotion x Difficulty (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Escalation Rate %')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEscalation Rate by Emotion x Difficulty:\")\n",
    "emotion_diff_esc.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-risk-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Emotion x Risk Level distribution.\n",
    "\"\"\"\n",
    "emotion_risk = pd.crosstab(df['emotion'], df['risk_level'], normalize='index') * 100\n",
    "\n",
    "for col in ['none', 'low', 'medium', 'high']:\n",
    "    if col not in emotion_risk.columns:\n",
    "        emotion_risk[col] = 0\n",
    "emotion_risk = emotion_risk[['none', 'low', 'medium', 'high']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(emotion_risk.values, cmap='RdYlGn_r', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(emotion_risk.columns)))\n",
    "ax.set_yticks(range(len(emotion_risk.index)))\n",
    "ax.set_xticklabels(emotion_risk.columns)\n",
    "ax.set_yticklabels(emotion_risk.index)\n",
    "\n",
    "for i in range(len(emotion_risk.index)):\n",
    "    for j in range(len(emotion_risk.columns)):\n",
    "        val = emotion_risk.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Risk Level')\n",
    "ax.set_ylabel('Emotion')\n",
    "ax.set_title('Risk Level Distribution by Emotion (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficulty-risk-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Difficulty x Risk Level distribution.\n",
    "\"\"\"\n",
    "diff_risk = pd.crosstab(df['difficulty'], df['risk_level'], normalize='index') * 100\n",
    "\n",
    "for col in ['none', 'low', 'medium', 'high']:\n",
    "    if col not in diff_risk.columns:\n",
    "        diff_risk[col] = 0\n",
    "diff_risk = diff_risk[['none', 'low', 'medium', 'high']]\n",
    "\n",
    "# Reorder index\n",
    "diff_order = ['low', 'medium', 'high']\n",
    "diff_risk = diff_risk.reindex([d for d in diff_order if d in diff_risk.index])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "im = ax.imshow(diff_risk.values, cmap='RdYlGn_r', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(diff_risk.columns)))\n",
    "ax.set_yticks(range(len(diff_risk.index)))\n",
    "ax.set_xticklabels(diff_risk.columns)\n",
    "ax.set_yticklabels(diff_risk.index)\n",
    "\n",
    "for i in range(len(diff_risk.index)):\n",
    "    for j in range(len(diff_risk.columns)):\n",
    "        val = diff_risk.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Risk Level')\n",
    "ax.set_ylabel('Difficulty')\n",
    "ax.set_title('Risk Level Distribution by Difficulty (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidence-emotion-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Confidence x Emotion distribution - does emotion affect classification certainty?\n",
    "\"\"\"\n",
    "conf_emotion = pd.crosstab(df['confidence'], df['emotion'], normalize='columns') * 100\n",
    "\n",
    "# Reorder index\n",
    "conf_order = ['high', 'medium', 'low']\n",
    "conf_emotion = conf_emotion.reindex([c for c in conf_order if c in conf_emotion.index])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(conf_emotion.values, cmap='RdYlGn', aspect='auto')\n",
    "\n",
    "ax.set_xticks(range(len(conf_emotion.columns)))\n",
    "ax.set_yticks(range(len(conf_emotion.index)))\n",
    "ax.set_xticklabels(conf_emotion.columns, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conf_emotion.index)\n",
    "\n",
    "for i in range(len(conf_emotion.index)):\n",
    "    for j in range(len(conf_emotion.columns)):\n",
    "        val = conf_emotion.iloc[i, j]\n",
    "        ax.text(j, i, f'{val:.0f}%', ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Confidence')\n",
    "ax.set_title('Confidence Distribution by Emotion (%)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, label='Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary statistics for categorical field correlations.\n",
    "\"\"\"\n",
    "print(\"=\"*70)\n",
    "print(\"CROSS-FIELD CORRELATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Escalation rates by various factors\n",
    "print(\"\\n1. ESCALATION RATES:\")\n",
    "print(f\"   Overall: {df['escalation_required'].mean()*100:.1f}%\")\n",
    "print(f\"   By emotion (highest): {df.groupby('emotion')['escalation_required'].mean().idxmax()} \"\n",
    "      f\"({df.groupby('emotion')['escalation_required'].mean().max()*100:.1f}%)\")\n",
    "print(f\"   By difficulty (highest): {df.groupby('difficulty')['escalation_required'].mean().idxmax()} \"\n",
    "      f\"({df.groupby('difficulty')['escalation_required'].mean().max()*100:.1f}%)\")\n",
    "\n",
    "# Average emotion intensity\n",
    "print(\"\\n2. EMOTION INTENSITY:\")\n",
    "print(f\"   Overall avg: {df['emotion_score'].mean():.2f}\")\n",
    "print(f\"   By difficulty:\")\n",
    "for diff in ['low', 'medium', 'high']:\n",
    "    subset = df[df['difficulty'] == diff]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"      {diff}: {subset['emotion_score'].mean():.2f}\")\n",
    "\n",
    "# Risk levels\n",
    "print(\"\\n3. RISK DISTRIBUTION:\")\n",
    "for risk in ['none', 'low', 'medium', 'high']:\n",
    "    count = (df['risk_level'] == risk).sum()\n",
    "    print(f\"   {risk}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# High-risk profile\n",
    "high_risk = df[df['risk_level'] == 'high']\n",
    "if len(high_risk) > 0:\n",
    "    print(\"\\n4. HIGH-RISK PROFILE:\")\n",
    "    print(f\"   Most common emotion: {high_risk['emotion'].mode().values[0] if len(high_risk['emotion'].mode()) > 0 else 'N/A'}\")\n",
    "    print(f\"   Most common topic: {high_risk['topic'].mode().values[0] if len(high_risk['topic'].mode()) > 0 else 'N/A'}\")\n",
    "    print(f\"   Escalation rate: {high_risk['escalation_required'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handler-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Handler Actionability\n",
    "\n",
    "Analyzing handler summary quality and actionability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handler-summary-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Handler summary length and quality analysis.\n",
    "\"\"\"\n",
    "df['summary_length'] = df['handler_summary'].fillna('').str.len()\n",
    "df['summary_words'] = df['handler_summary'].fillna('').str.split().str.len()\n",
    "\n",
    "print(\"Handler Summary Statistics:\")\n",
    "print(f\"  Average length (chars): {df['summary_length'].mean():.0f}\")\n",
    "print(f\"  Average length (words): {df['summary_words'].mean():.0f}\")\n",
    "print(f\"  Min words: {df['summary_words'].min()}\")\n",
    "print(f\"  Max words: {df['summary_words'].max()}\")\n",
    "print(f\"  Under 35 words (target): {(df['summary_words'] <= 35).sum()} ({(df['summary_words'] <= 35).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handler-word-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Handler summary word count distribution.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.hist(df['summary_words'], bins=30, color='#3498db', edgecolor='white', alpha=0.7)\n",
    "ax.axvline(x=35, color='red', linestyle='--', linewidth=2, label='Target max (35 words)')\n",
    "ax.axvline(x=df['summary_words'].mean(), color='green', linestyle='-', linewidth=2, \n",
    "           label=f'Mean ({df[\"summary_words\"].mean():.0f} words)')\n",
    "\n",
    "ax.set_xlabel('Word Count')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Handler Summary Word Count Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-per-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Actions per conversation distribution.\n",
    "\"\"\"\n",
    "df['num_actions'] = df['operational_actions'].apply(len)\n",
    "\n",
    "action_count_dist = df['num_actions'].value_counts().sort_index()\n",
    "\n",
    "print(\"Actions per Conversation:\")\n",
    "print(f\"  Average: {df['num_actions'].mean():.2f}\")\n",
    "print(f\"  Mode: {df['num_actions'].mode().values[0]}\")\n",
    "print(f\"  Max: {df['num_actions'].max()}\")\n",
    "print(f\"  Zero actions: {(df['num_actions'] == 0).sum()} ({(df['num_actions'] == 0).mean()*100:.1f}%)\")\n",
    "print(f\"\\nDistribution:\")\n",
    "for n_actions, count in action_count_dist.items():\n",
    "    print(f\"  {n_actions} action(s): {count} ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dashboard-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Model Health Dashboard\n",
    "\n",
    "Summary metrics and health indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "health-dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Health Dashboard - Summary metrics.\n",
    "\"\"\"\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL HEALTH DASHBOARD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Classification quality\n",
    "print(\"\\n1. CLASSIFICATION QUALITY\")\n",
    "print(f\"   Total conversations: {len(df)}\")\n",
    "print(f\"   High confidence rate: {(df['confidence'] == 'high').mean()*100:.1f}%\")\n",
    "print(f\"   Low confidence rate: {(df['confidence'] == 'low').mean()*100:.1f}%\")\n",
    "print(f\"   Catch-all rate: {(df['topic'] == 'General Enquiries & Multi-Intent').mean()*100:.1f}%\")\n",
    "\n",
    "# Operational signals\n",
    "print(\"\\n2. OPERATIONAL SIGNALS\")\n",
    "print(f\"   Escalation rate: {df['escalation_required'].mean()*100:.1f}%\")\n",
    "print(f\"   High risk rate: {(df['risk_level'] == 'high').mean()*100:.1f}%\")\n",
    "print(f\"   Avg emotion intensity: {df['emotion_score'].mean():.2f} (0-5 scale)\")\n",
    "print(f\"   High difficulty rate: {(df['difficulty'] == 'high').mean()*100:.1f}%\")\n",
    "\n",
    "# Handler output quality\n",
    "print(\"\\n3. HANDLER OUTPUT QUALITY\")\n",
    "print(f\"   Avg summary length: {df['summary_words'].mean():.0f} words\")\n",
    "print(f\"   Summaries within target: {(df['summary_words'] <= 35).mean()*100:.1f}%\")\n",
    "print(f\"   Avg actions per conversation: {df['num_actions'].mean():.2f}\")\n",
    "\n",
    "# Emotion distribution\n",
    "print(\"\\n4. EMOTION DISTRIBUTION\")\n",
    "for emotion, count in df['emotion'].value_counts().items():\n",
    "    print(f\"   {emotion}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Topic distribution (top 5)\n",
    "print(\"\\n5. TOP 5 TOPICS\")\n",
    "for topic, count in df['topic'].value_counts().head(5).items():\n",
    "    print(f\"   {topic}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "health-indicators",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Health indicator flags.\n",
    "\"\"\"\n",
    "print(\"HEALTH INDICATORS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "indicators = []\n",
    "\n",
    "# High confidence check\n",
    "high_conf_rate = (df['confidence'] == 'high').mean()\n",
    "if high_conf_rate >= 0.85:\n",
    "    indicators.append((\"[PASS]\", f\"High confidence rate: {high_conf_rate*100:.1f}% (target: >85%)\"))\n",
    "else:\n",
    "    indicators.append((\"[WARN]\", f\"High confidence rate: {high_conf_rate*100:.1f}% (target: >85%)\"))\n",
    "\n",
    "# Low confidence check\n",
    "low_conf_rate = (df['confidence'] == 'low').mean()\n",
    "if low_conf_rate <= 0.15:\n",
    "    indicators.append((\"[PASS]\", f\"Low confidence rate: {low_conf_rate*100:.1f}% (target: <15%)\"))\n",
    "else:\n",
    "    indicators.append((\"[WARN]\", f\"Low confidence rate: {low_conf_rate*100:.1f}% (target: <15%)\"))\n",
    "\n",
    "# Catch-all rate check\n",
    "catchall_rate = (df['topic'] == 'General Enquiries & Multi-Intent').mean()\n",
    "if catchall_rate <= 0.20:\n",
    "    indicators.append((\"[PASS]\", f\"Catch-all rate: {catchall_rate*100:.1f}% (target: <20%)\"))\n",
    "else:\n",
    "    indicators.append((\"[WARN]\", f\"Catch-all rate: {catchall_rate*100:.1f}% (target: <20%)\"))\n",
    "\n",
    "# Escalation sanity check\n",
    "esc_rate = df['escalation_required'].mean()\n",
    "if 0.01 <= esc_rate <= 0.30:\n",
    "    indicators.append((\"[PASS]\", f\"Escalation rate: {esc_rate*100:.1f}% (reasonable range: 1-30%)\"))\n",
    "else:\n",
    "    indicators.append((\"[INFO]\", f\"Escalation rate: {esc_rate*100:.1f}% (typical range: 1-30%)\"))\n",
    "\n",
    "# Summary length check\n",
    "summary_compliance = (df['summary_words'] <= 35).mean()\n",
    "if summary_compliance >= 0.90:\n",
    "    indicators.append((\"[PASS]\", f\"Summary length compliance: {summary_compliance*100:.1f}% (target: >90%)\"))\n",
    "else:\n",
    "    indicators.append((\"[WARN]\", f\"Summary length compliance: {summary_compliance*100:.1f}% (target: >90%)\"))\n",
    "\n",
    "for status, message in indicators:\n",
    "    print(f\"{status} {message}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
