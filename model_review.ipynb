{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Model Output Analysis: Conversation Topic Classifier with Operational Enrichment\n",
    "\n",
    "This notebook performs comprehensive analysis on the AI classification outputs to evaluate:\n",
    "- **Topic Classification Quality**: Label distribution, confidence calibration, accuracy\n",
    "- **Operational Insights**: Escalation patterns, risk assessment, root causes\n",
    "- **Routing Recommendations**: Action mapping, workflow assignment\n",
    "- **Handler Actionability**: Summary quality, recommended actions\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Setup & Data Loading** - Import libraries, load and validate data\n",
    "2. **Topic Distribution Analysis** - Main drivers of contact\n",
    "3. **Confidence Analysis** - Model certainty patterns\n",
    "4. **Escalation Analysis** - Risk and escalation patterns\n",
    "5. **Routing Analysis** - Operational actions and workflow mapping\n",
    "6. **Root Cause Analysis** - Primary issue drivers\n",
    "7. **Handler Actionability** - Summary and action quality\n",
    "8. **Model Health Dashboard** - Summary metrics\n",
    "9. **Answers to Taxonomy Goals** - How outputs support business objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import required libraries for data analysis and visualization.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import warnings\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Chart export settings\n",
    "EXPORT_CHARTS = False  # Set to True to save charts as PNG files\n",
    "CHART_DPI = 150\n",
    "\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the model output dataset with new operational enrichment fields.\n",
    "\n",
    "Expected columns:\n",
    "- conversation_id, conversation: Original data\n",
    "- topic, confidence, rationale: Core classification\n",
    "- handler_summary: Call-handler-friendly summary\n",
    "- emotion, difficulty: Customer state assessment\n",
    "- operational_actions: List of recommended actions\n",
    "- risk_level, escalation_required, escalation_flags: Risk assessment\n",
    "- root_cause_code, root_cause_detail: Root cause analysis\n",
    "\"\"\"\n",
    "# Configuration - adjust paths as needed\n",
    "AI_LABELS_PATH = \"data/conversations_ai_classified_.csv\"\n",
    "MANUAL_LABELS_PATH = \"data/conversations_manually_classified.csv\"\n",
    "\n",
    "# Load AI classifications\n",
    "df = pd.read_csv(AI_LABELS_PATH)\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} conversations\")\n",
    "print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "for col in df.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate-columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Validate expected columns exist and identify optional columns.\n",
    "\"\"\"\n",
    "# Define expected columns by category\n",
    "REQUIRED_COLUMNS = ['conversation_id', 'conversation', 'topic', 'confidence', 'rationale']\n",
    "OPERATIONAL_COLUMNS = [\n",
    "    'handler_summary', 'emotion', 'difficulty', 'operational_actions',\n",
    "    'risk_level', 'escalation_required', 'escalation_flags',\n",
    "    'root_cause_code', 'root_cause_detail'\n",
    "]\n",
    "\n",
    "# Check required columns\n",
    "missing_required = [col for col in REQUIRED_COLUMNS if col not in df.columns]\n",
    "if missing_required:\n",
    "    raise ValueError(f\"Missing required columns: {missing_required}\")\n",
    "print(\"‚úì All required columns present\")\n",
    "\n",
    "# Check operational columns\n",
    "present_operational = [col for col in OPERATIONAL_COLUMNS if col in df.columns]\n",
    "missing_operational = [col for col in OPERATIONAL_COLUMNS if col not in df.columns]\n",
    "\n",
    "print(f\"\\nOperational columns present ({len(present_operational)}/{len(OPERATIONAL_COLUMNS)}):\")\n",
    "for col in present_operational:\n",
    "    print(f\"  ‚úì {col}\")\n",
    "\n",
    "if missing_operational:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing operational columns (will skip related analyses):\")\n",
    "    for col in missing_operational:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "# Feature flags for conditional analysis\n",
    "HAS_ESCALATION = 'escalation_required' in df.columns\n",
    "HAS_ACTIONS = 'operational_actions' in df.columns\n",
    "HAS_ROOT_CAUSE = 'root_cause_code' in df.columns\n",
    "HAS_EMOTION = 'emotion' in df.columns\n",
    "HAS_HANDLER_SUMMARY = 'handler_summary' in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse-list-columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parse list columns (operational_actions, escalation_flags) from string representation.\n",
    "Pandas serializes lists as strings in CSV - we need to convert them back.\n",
    "\"\"\"\n",
    "def safe_parse_list(val):\n",
    "    \"\"\"Safely parse a string representation of a list.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            return parsed if isinstance(parsed, list) else []\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "# Parse list columns if present\n",
    "if HAS_ACTIONS:\n",
    "    df['operational_actions_list'] = df['operational_actions'].apply(safe_parse_list)\n",
    "    df['num_actions'] = df['operational_actions_list'].apply(len)\n",
    "    print(f\"Parsed operational_actions: {df['num_actions'].sum():,} total actions across {(df['num_actions'] > 0).sum():,} conversations\")\n",
    "\n",
    "if HAS_ESCALATION and 'escalation_flags' in df.columns:\n",
    "    df['escalation_flags_list'] = df['escalation_flags'].apply(safe_parse_list)\n",
    "    df['num_flags'] = df['escalation_flags_list'].apply(len)\n",
    "    print(f\"Parsed escalation_flags: {df['num_flags'].sum():,} total flags across {(df['num_flags'] > 0).sum():,} conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-quality-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check for missing values and data quality issues.\n",
    "\"\"\"\n",
    "# Missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(1)\n",
    "missing_report = pd.DataFrame({'Missing': missing, 'Pct': missing_pct})\n",
    "missing_report = missing_report[missing_report['Missing'] > 0]\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "if len(missing_report) > 0:\n",
    "    print(missing_report)\n",
    "else:\n",
    "    print(\"  No missing values found.\")\n",
    "\n",
    "# Check for ERROR classifications (failed API calls)\n",
    "error_count = (df['topic'] == 'ERROR').sum()\n",
    "if error_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: {error_count} conversations failed classification (topic='ERROR')\")\n",
    "else:\n",
    "    print(\"\\n‚úì No classification errors found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "topic-distribution-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Topic Distribution Analysis\n",
    "\n",
    "Understanding how conversations are distributed across topic categories reveals the **main drivers of customer contact**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "topic-counts",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate topic distribution statistics.\n",
    "\"\"\"\n",
    "# Topic counts and percentages\n",
    "topic_counts = df['topic'].value_counts()\n",
    "topic_pcts = df['topic'].value_counts(normalize=True) * 100\n",
    "\n",
    "topic_dist = pd.DataFrame({\n",
    "    'Count': topic_counts,\n",
    "    'Percentage': topic_pcts.round(1)\n",
    "})\n",
    "\n",
    "print(f\"Total unique topics: {len(topic_counts)}\")\n",
    "print(f\"\\nTopic Distribution:\")\n",
    "topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "topic-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize topic distribution as a horizontal bar chart - Main Drivers of Contact.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Sort by count for better visualization\n",
    "topic_counts_sorted = topic_counts.sort_values(ascending=True)\n",
    "\n",
    "# Create horizontal bar chart with color gradient\n",
    "colors = plt.cm.Blues(np.linspace(0.3, 0.9, len(topic_counts_sorted)))\n",
    "bars = ax.barh(range(len(topic_counts_sorted)), topic_counts_sorted.values, color=colors)\n",
    "\n",
    "# Set y-tick labels\n",
    "ax.set_yticks(range(len(topic_counts_sorted)))\n",
    "ax.set_yticklabels(topic_counts_sorted.index)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, (bar, count) in enumerate(zip(bars, topic_counts_sorted.values)):\n",
    "    pct = count / len(df) * 100\n",
    "    ax.text(bar.get_width() + 5, bar.get_y() + bar.get_height()/2, \n",
    "            f'{count} ({pct:.1f}%)', va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Number of Conversations')\n",
    "ax.set_title('Main Drivers of Contact: Topic Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(topic_counts_sorted.values) * 1.25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if EXPORT_CHARTS:\n",
    "    plt.savefig('charts/topic_distribution.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Top 3 Contact Drivers:\")\n",
    "for i, (topic, count) in enumerate(topic_counts.head(3).items(), 1):\n",
    "    print(f\"   {i}. {topic}: {count} ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidence-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Confidence Analysis\n",
    "\n",
    "Analyzing confidence levels helps understand:\n",
    "- Overall model certainty\n",
    "- Which topics are harder to classify\n",
    "- Potential ambiguity in the taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidence-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overall confidence level distribution.\n",
    "\"\"\"\n",
    "# Confidence counts - handle any confidence level present\n",
    "confidence_order = ['high', 'medium', 'low']\n",
    "conf_counts = df['confidence'].value_counts()\n",
    "\n",
    "# Reindex to ensure consistent order\n",
    "for level in confidence_order:\n",
    "    if level not in conf_counts.index:\n",
    "        conf_counts[level] = 0\n",
    "conf_counts = conf_counts.reindex(confidence_order)\n",
    "\n",
    "conf_pcts = (conf_counts / len(df) * 100).round(1)\n",
    "\n",
    "conf_summary = pd.DataFrame({\n",
    "    'Count': conf_counts,\n",
    "    'Percentage': conf_pcts\n",
    "})\n",
    "\n",
    "print(\"Overall Confidence Distribution:\")\n",
    "conf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidence-bar-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize overall confidence distribution.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "colors = {'high': '#27ae60', 'medium': '#f39c12', 'low': '#e74c3c'}\n",
    "bar_colors = [colors.get(c, 'gray') for c in conf_counts.index]\n",
    "bars = ax.bar(conf_counts.index, conf_counts.values, color=bar_colors, edgecolor='white', linewidth=2)\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count, pct in zip(bars, conf_counts.values, conf_pcts.values):\n",
    "    if count > 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(conf_counts)*0.02, \n",
    "                f'{count}\\n({pct}%)', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Confidence Level')\n",
    "ax.set_ylabel('Number of Conversations')\n",
    "ax.set_title('Overall Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(conf_counts.values) * 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if EXPORT_CHARTS:\n",
    "    plt.savefig('charts/confidence_distribution.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidence-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Confidence distribution broken down by topic (stacked bar chart).\n",
    "\"\"\"\n",
    "# Cross-tabulation of topic x confidence\n",
    "conf_by_topic = pd.crosstab(df['topic'], df['confidence'])\n",
    "\n",
    "# Ensure all confidence levels are present\n",
    "for col in ['high', 'medium', 'low']:\n",
    "    if col not in conf_by_topic.columns:\n",
    "        conf_by_topic[col] = 0\n",
    "conf_by_topic = conf_by_topic[['high', 'medium', 'low']]\n",
    "\n",
    "# Calculate percentages\n",
    "conf_by_topic_pct = conf_by_topic.div(conf_by_topic.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"Confidence Distribution by Topic (counts):\")\n",
    "conf_by_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidence-by-topic-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stacked bar chart showing confidence levels per topic.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Sort topics by high-confidence rate (descending)\n",
    "topic_order = conf_by_topic_pct['high'].sort_values(ascending=True).index\n",
    "conf_by_topic_sorted = conf_by_topic_pct.reindex(topic_order)\n",
    "\n",
    "# Create stacked horizontal bar chart\n",
    "colors = {'high': '#27ae60', 'medium': '#f39c12', 'low': '#e74c3c'}\n",
    "\n",
    "y_pos = range(len(conf_by_topic_sorted))\n",
    "left = np.zeros(len(conf_by_topic_sorted))\n",
    "\n",
    "for conf_level in ['high', 'medium', 'low']:\n",
    "    values = conf_by_topic_sorted[conf_level].values\n",
    "    ax.barh(y_pos, values, left=left, label=conf_level.capitalize(), color=colors[conf_level])\n",
    "    left += values\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(conf_by_topic_sorted.index)\n",
    "ax.set_xlabel('Percentage')\n",
    "ax.set_title('Confidence Distribution by Topic', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Add percentage labels for high confidence\n",
    "for i, topic in enumerate(conf_by_topic_sorted.index):\n",
    "    high_pct = conf_by_topic_sorted.loc[topic, 'high']\n",
    "    if high_pct > 15:\n",
    "        ax.text(high_pct/2, i, f'{high_pct:.0f}%', ha='center', va='center', \n",
    "                fontsize=8, color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if EXPORT_CHARTS:\n",
    "    plt.savefig('charts/confidence_by_topic.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lowest-confidence-topics",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Topics with lowest confidence - candidates for taxonomy refinement.\n",
    "\"\"\"\n",
    "# Calculate low+medium confidence rate\n",
    "low_med_rate = (conf_by_topic_pct['low'] + conf_by_topic_pct['medium']).sort_values(ascending=False)\n",
    "\n",
    "low_conf_df = pd.DataFrame({\n",
    "    'Topic': low_med_rate.index,\n",
    "    'Low+Med Rate (%)': low_med_rate.values.round(1),\n",
    "    'High (%)': conf_by_topic_pct['high'].reindex(low_med_rate.index).values.round(1),\n",
    "    'Total': conf_by_topic.sum(axis=1).reindex(low_med_rate.index).values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(\"‚ö†Ô∏è  Topics by Uncertainty (candidates for taxonomy refinement):\")\n",
    "low_conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "escalation-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Escalation Analysis\n",
    "\n",
    "Analyze escalation patterns to understand:\n",
    "- Which conversations need human intervention\n",
    "- Risk level distribution across topics\n",
    "- Common escalation triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overall escalation statistics.\n",
    "\"\"\"\n",
    "if HAS_ESCALATION:\n",
    "    # Escalation rate\n",
    "    esc_count = df['escalation_required'].sum()\n",
    "    esc_rate = esc_count / len(df) * 100\n",
    "    \n",
    "    print(\"Escalation Overview\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Conversations requiring escalation: {esc_count:,} ({esc_rate:.1f}%)\")\n",
    "    print(f\"Conversations not requiring escalation: {len(df) - esc_count:,} ({100-esc_rate:.1f}%)\")\n",
    "    \n",
    "    # Risk level distribution\n",
    "    if 'risk_level' in df.columns:\n",
    "        print(f\"\\nRisk Level Distribution:\")\n",
    "        risk_counts = df['risk_level'].value_counts()\n",
    "        for level, count in risk_counts.items():\n",
    "            print(f\"  {level}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Escalation data not available - skipping escalation analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-flags-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Breakdown of escalation flags - what triggers escalation.\n",
    "\"\"\"\n",
    "if HAS_ESCALATION and 'escalation_flags_list' in df.columns:\n",
    "    # Flatten all flags and count occurrences\n",
    "    all_flags = []\n",
    "    for flags in df['escalation_flags_list']:\n",
    "        all_flags.extend(flags)\n",
    "    \n",
    "    if all_flags:\n",
    "        flag_counts = pd.Series(all_flags).value_counts()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        colors = plt.cm.Reds(np.linspace(0.4, 0.9, len(flag_counts)))\n",
    "        bars = ax.barh(range(len(flag_counts)), flag_counts.values, color=colors[::-1])\n",
    "        \n",
    "        ax.set_yticks(range(len(flag_counts)))\n",
    "        ax.set_yticklabels(flag_counts.index)\n",
    "        ax.set_xlabel('Count')\n",
    "        ax.set_title('Escalation Flags: What Triggers Escalation', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add count labels\n",
    "        for bar, count in zip(bars, flag_counts.values):\n",
    "            ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{count}', va='center', fontsize=9)\n",
    "        \n",
    "        ax.set_xlim(0, max(flag_counts.values) * 1.15)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if EXPORT_CHARTS:\n",
    "            plt.savefig('charts/escalation_flags.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nTop Escalation Triggers:\")\n",
    "        for flag, count in flag_counts.head(5).items():\n",
    "            print(f\"  ‚Ä¢ {flag}: {count} occurrences\")\n",
    "    else:\n",
    "        print(\"No escalation flags found in the dataset.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Escalation flags not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Escalation rate by topic - which topics require most human intervention.\n",
    "\"\"\"\n",
    "if HAS_ESCALATION:\n",
    "    # Calculate escalation rate per topic\n",
    "    esc_by_topic = df.groupby('topic')['escalation_required'].agg(['sum', 'count'])\n",
    "    esc_by_topic['rate'] = (esc_by_topic['sum'] / esc_by_topic['count'] * 100).round(1)\n",
    "    esc_by_topic = esc_by_topic.sort_values('rate', ascending=True)\n",
    "    esc_by_topic.columns = ['Escalations', 'Total', 'Rate (%)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    # Color bars by escalation rate\n",
    "    colors = plt.cm.RdYlGn_r(esc_by_topic['Rate (%)'].values / 100)\n",
    "    bars = ax.barh(range(len(esc_by_topic)), esc_by_topic['Rate (%)'].values, color=colors)\n",
    "    \n",
    "    ax.set_yticks(range(len(esc_by_topic)))\n",
    "    ax.set_yticklabels(esc_by_topic.index)\n",
    "    ax.set_xlabel('Escalation Rate (%)')\n",
    "    ax.set_title('Escalation Rate by Topic', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add rate labels\n",
    "    for i, (bar, rate) in enumerate(zip(bars, esc_by_topic['Rate (%)'].values)):\n",
    "        count = esc_by_topic.iloc[i]['Escalations']\n",
    "        ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "                f'{rate:.0f}% (n={int(count)})', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlim(0, max(esc_by_topic['Rate (%)'].values) * 1.3 if max(esc_by_topic['Rate (%)'].values) > 0 else 10)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if EXPORT_CHARTS:\n",
    "        plt.savefig('charts/escalation_by_topic.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nEscalation Rate by Topic:\")\n",
    "    print(esc_by_topic.sort_values('Rate (%)', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "risk-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Risk level distribution by topic.\n",
    "\"\"\"\n",
    "if 'risk_level' in df.columns:\n",
    "    # Cross-tabulation of topic x risk_level\n",
    "    risk_order = ['none', 'low', 'medium', 'high']\n",
    "    risk_by_topic = pd.crosstab(df['topic'], df['risk_level'])\n",
    "    \n",
    "    # Ensure all risk levels present\n",
    "    for level in risk_order:\n",
    "        if level not in risk_by_topic.columns:\n",
    "            risk_by_topic[level] = 0\n",
    "    risk_by_topic = risk_by_topic[[col for col in risk_order if col in risk_by_topic.columns]]\n",
    "    \n",
    "    # Calculate percentages\n",
    "    risk_by_topic_pct = risk_by_topic.div(risk_by_topic.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Sort by high+medium risk rate\n",
    "    if 'high' in risk_by_topic_pct.columns and 'medium' in risk_by_topic_pct.columns:\n",
    "        sort_key = risk_by_topic_pct['high'] + risk_by_topic_pct['medium']\n",
    "    elif 'high' in risk_by_topic_pct.columns:\n",
    "        sort_key = risk_by_topic_pct['high']\n",
    "    else:\n",
    "        sort_key = risk_by_topic_pct.iloc[:, -1]\n",
    "    \n",
    "    risk_by_topic_sorted = risk_by_topic_pct.loc[sort_key.sort_values(ascending=True).index]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    risk_colors = {'none': '#95a5a6', 'low': '#27ae60', 'medium': '#f39c12', 'high': '#e74c3c'}\n",
    "    \n",
    "    y_pos = range(len(risk_by_topic_sorted))\n",
    "    left = np.zeros(len(risk_by_topic_sorted))\n",
    "    \n",
    "    for level in risk_order:\n",
    "        if level in risk_by_topic_sorted.columns:\n",
    "            values = risk_by_topic_sorted[level].values\n",
    "            ax.barh(y_pos, values, left=left, label=level.capitalize(), color=risk_colors[level])\n",
    "            left += values\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(risk_by_topic_sorted.index)\n",
    "    ax.set_xlabel('Percentage')\n",
    "    ax.set_title('Risk Level Distribution by Topic', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_xlim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if EXPORT_CHARTS:\n",
    "        plt.savefig('charts/risk_by_topic.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Risk level data not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "routing-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Routing Analysis\n",
    "\n",
    "Analyze operational actions to understand:\n",
    "- What actions are most commonly recommended\n",
    "- How actions map to topics\n",
    "- Proposed routing rules for automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overall operational actions frequency.\n",
    "\"\"\"\n",
    "if HAS_ACTIONS and 'operational_actions_list' in df.columns:\n",
    "    # Flatten all actions\n",
    "    all_actions = []\n",
    "    for actions in df['operational_actions_list']:\n",
    "        all_actions.extend(actions)\n",
    "    \n",
    "    if all_actions:\n",
    "        action_counts = pd.Series(all_actions).value_counts()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        colors = plt.cm.Greens(np.linspace(0.3, 0.9, len(action_counts)))\n",
    "        bars = ax.barh(range(len(action_counts)), action_counts.values, color=colors[::-1])\n",
    "        \n",
    "        ax.set_yticks(range(len(action_counts)))\n",
    "        ax.set_yticklabels(action_counts.index)\n",
    "        ax.set_xlabel('Count')\n",
    "        ax.set_title('Operational Actions: Overall Frequency', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add count labels\n",
    "        for bar, count in zip(bars, action_counts.values):\n",
    "            pct = count / len(df) * 100\n",
    "            ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{count} ({pct:.1f}%)', va='center', fontsize=8)\n",
    "        \n",
    "        ax.set_xlim(0, max(action_counts.values) * 1.2)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if EXPORT_CHARTS:\n",
    "            plt.savefig('charts/actions_overall.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nTotal actions recommended: {len(all_actions):,}\")\n",
    "        print(f\"Unique action types: {len(action_counts)}\")\n",
    "        print(f\"Average actions per conversation: {len(all_actions)/len(df):.2f}\")\n",
    "    else:\n",
    "        print(\"No operational actions found in the dataset.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Operational actions not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Top operational actions by topic.\n",
    "\"\"\"\n",
    "if HAS_ACTIONS and 'operational_actions_list' in df.columns:\n",
    "    # Build topic -> action mapping\n",
    "    topic_actions = {}\n",
    "    for _, row in df.iterrows():\n",
    "        topic = row['topic']\n",
    "        actions = row['operational_actions_list']\n",
    "        if topic not in topic_actions:\n",
    "            topic_actions[topic] = []\n",
    "        topic_actions[topic].extend(actions)\n",
    "    \n",
    "    # Get top 3 actions per topic\n",
    "    print(\"Top 3 Operational Actions by Topic:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    summary_data = []\n",
    "    for topic in topic_counts.index:\n",
    "        if topic in topic_actions and topic_actions[topic]:\n",
    "            actions = pd.Series(topic_actions[topic]).value_counts().head(3)\n",
    "            top_actions = ', '.join([f\"{a} ({c})\" for a, c in actions.items()])\n",
    "            summary_data.append({'Topic': topic, 'Top Actions': top_actions})\n",
    "            print(f\"\\n{topic}:\")\n",
    "            for action, count in actions.items():\n",
    "                print(f\"  ‚Ä¢ {action}: {count}\")\n",
    "    \n",
    "    actions_summary_df = pd.DataFrame(summary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "routing-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Proposed routing table: Topic ‚Üí Workflow/Agent mapping.\n",
    "\"\"\"\n",
    "# Define routing rules based on topic patterns\n",
    "# This is an example - adjust based on actual business workflows\n",
    "\n",
    "routing_rules = {\n",
    "    'Account Access & Customer Profile': 'Auth Support Bot',\n",
    "    'Orders, Shipping & Delivery': 'Order Management Bot',\n",
    "    'Returns, Refunds & Exchanges': 'Returns Specialist',\n",
    "    'Product Defects & Fulfillment Errors': 'Quality Team',\n",
    "    'Billing, Charges & Price Discrepancies': 'Billing Specialist',\n",
    "    'Technical & Platform Issues': 'Tech Support Bot',\n",
    "    'Product Information & Availability': 'Product Info Bot',\n",
    "    'Promotions, Discounts & Loyalty': 'Loyalty Team',\n",
    "    'Complaints, Escalations & Negative Feedback': 'Senior Agent',\n",
    "    'General Enquiries & Multi-Intent': 'General Support Bot'\n",
    "}\n",
    "\n",
    "# Build routing coverage table\n",
    "routing_data = []\n",
    "for topic in topic_counts.index:\n",
    "    count = topic_counts[topic]\n",
    "    pct = count / len(df) * 100\n",
    "    workflow = routing_rules.get(topic, 'Unassigned')\n",
    "    routing_data.append({\n",
    "        'Topic': topic,\n",
    "        'Count': count,\n",
    "        'Pct': f\"{pct:.1f}%\",\n",
    "        'Suggested Workflow': workflow\n",
    "    })\n",
    "\n",
    "routing_df = pd.DataFrame(routing_data)\n",
    "\n",
    "print(\"Proposed Routing Table: Topic ‚Üí Workflow/Agent\")\n",
    "print(\"=\" * 80)\n",
    "print(routing_df.to_string(index=False))\n",
    "\n",
    "# Coverage analysis\n",
    "unassigned = routing_df[routing_df['Suggested Workflow'] == 'Unassigned']['Count'].sum()\n",
    "coverage = (len(df) - unassigned) / len(df) * 100\n",
    "\n",
    "print(f\"\\nüìä Routing Coverage: {coverage:.1f}% of conversations have assigned workflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "root-cause-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Root Cause Analysis\n",
    "\n",
    "Understand the underlying reasons for customer contacts:\n",
    "- Most common root causes overall\n",
    "- Root cause distribution by topic\n",
    "- Patterns for proactive issue prevention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root-cause-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overall root cause code distribution.\n",
    "\"\"\"\n",
    "if HAS_ROOT_CAUSE:\n",
    "    root_cause_counts = df['root_cause_code'].value_counts()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    colors = plt.cm.Oranges(np.linspace(0.3, 0.9, len(root_cause_counts)))\n",
    "    bars = ax.barh(range(len(root_cause_counts)), root_cause_counts.values, color=colors[::-1])\n",
    "    \n",
    "    ax.set_yticks(range(len(root_cause_counts)))\n",
    "    ax.set_yticklabels(root_cause_counts.index)\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_title('Root Cause Codes: Overall Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar, count in zip(bars, root_cause_counts.values):\n",
    "        pct = count / len(df) * 100\n",
    "        ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                f'{count} ({pct:.1f}%)', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlim(0, max(root_cause_counts.values) * 1.2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if EXPORT_CHARTS:\n",
    "        plt.savefig('charts/root_cause_overall.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTop 5 Root Causes:\")\n",
    "    for cause, count in root_cause_counts.head(5).items():\n",
    "        print(f\"  {cause}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Root cause data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root-cause-by-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Root cause distribution by topic (cross-tab heatmap-style table).\n",
    "\"\"\"\n",
    "if HAS_ROOT_CAUSE:\n",
    "    # Cross-tabulation of topic x root_cause_code\n",
    "    root_cause_by_topic = pd.crosstab(df['topic'], df['root_cause_code'])\n",
    "    \n",
    "    # Show as styled table (numeric values)\n",
    "    print(\"Topic vs Root Cause Cross-tabulation:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get top 5 root causes for display\n",
    "    top_causes = root_cause_counts.head(8).index.tolist()\n",
    "    display_crosstab = root_cause_by_topic[top_causes] if all(c in root_cause_by_topic.columns for c in top_causes) else root_cause_by_topic.iloc[:, :8]\n",
    "    \n",
    "    print(display_crosstab)\n",
    "    \n",
    "    # Heatmap visualization\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Normalize by row (topic) to show percentages\n",
    "    root_cause_pct = display_crosstab.div(display_crosstab.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Create heatmap using imshow\n",
    "    im = ax.imshow(root_cause_pct.values, cmap='YlOrRd', aspect='auto')\n",
    "    \n",
    "    # Set tick labels\n",
    "    ax.set_xticks(range(len(root_cause_pct.columns)))\n",
    "    ax.set_xticklabels(root_cause_pct.columns, rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_yticks(range(len(root_cause_pct.index)))\n",
    "    ax.set_yticklabels(root_cause_pct.index, fontsize=9)\n",
    "    \n",
    "    # Add percentage text\n",
    "    for i in range(len(root_cause_pct.index)):\n",
    "        for j in range(len(root_cause_pct.columns)):\n",
    "            val = root_cause_pct.iloc[i, j]\n",
    "            if val > 5:  # Only show if > 5%\n",
    "                text_color = 'white' if val > 30 else 'black'\n",
    "                ax.text(j, i, f'{val:.0f}%', ha='center', va='center', color=text_color, fontsize=7)\n",
    "    \n",
    "    ax.set_title('Root Cause Distribution by Topic (% within topic)', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax, label='Percentage')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if EXPORT_CHARTS:\n",
    "        plt.savefig('charts/root_cause_heatmap.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handler-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Handler Actionability\n",
    "\n",
    "Evaluate how actionable the enriched outputs are for call handlers:\n",
    "- Summary quality and length\n",
    "- Action recommendations coverage\n",
    "- Example records for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handler-summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Handler summary quality metrics.\n",
    "\"\"\"\n",
    "if HAS_HANDLER_SUMMARY:\n",
    "    df['summary_words'] = df['handler_summary'].fillna('').str.split().str.len()\n",
    "    df['summary_chars'] = df['handler_summary'].fillna('').str.len()\n",
    "    \n",
    "    print(\"Handler Summary Statistics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Average length: {df['summary_words'].mean():.1f} words ({df['summary_chars'].mean():.0f} chars)\")\n",
    "    print(f\"Min/Max words: {df['summary_words'].min()} / {df['summary_words'].max()}\")\n",
    "    print(f\"Target: ‚â§35 words\")\n",
    "    \n",
    "    over_limit = (df['summary_words'] > 35).sum()\n",
    "    print(f\"\\nSummaries over 35 words: {over_limit} ({over_limit/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Distribution histogram\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.hist(df['summary_words'], bins=20, color='steelblue', edgecolor='white', alpha=0.7)\n",
    "    ax.axvline(35, color='red', linestyle='--', linewidth=2, label='Target max (35 words)')\n",
    "    ax.axvline(df['summary_words'].mean(), color='orange', linestyle='--', linewidth=2, label=f'Mean ({df[\"summary_words\"].mean():.0f})')\n",
    "    ax.set_xlabel('Word Count')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Handler Summary Length Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Handler summary not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Customer emotion distribution.\n",
    "\"\"\"\n",
    "if HAS_EMOTION:\n",
    "    emotion_counts = df['emotion'].value_counts()\n",
    "    \n",
    "    # Color map for emotions\n",
    "    emotion_colors = {\n",
    "        'calm': '#27ae60',\n",
    "        'confused': '#3498db', \n",
    "        'frustrated': '#f39c12',\n",
    "        'angry': '#e74c3c',\n",
    "        'anxious': '#9b59b6',\n",
    "        'urgent': '#c0392b'\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors = [emotion_colors.get(e, '#95a5a6') for e in emotion_counts.index]\n",
    "    bars = ax.bar(emotion_counts.index, emotion_counts.values, color=colors, edgecolor='white', linewidth=2)\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar, count in zip(bars, emotion_counts.values):\n",
    "        pct = count / len(df) * 100\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(emotion_counts)*0.02,\n",
    "                f'{count}\\n({pct:.1f}%)', ha='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Customer Emotion')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Customer Emotion Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim(0, max(emotion_counts.values) * 1.2)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if EXPORT_CHARTS:\n",
    "        plt.savefig('charts/emotion_distribution.png', dpi=CHART_DPI, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Emotion data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actionability-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example records showing actionable enrichment for handlers.\n",
    "\"\"\"\n",
    "# Select columns to display\n",
    "display_cols = ['conversation_id', 'topic']\n",
    "\n",
    "if HAS_HANDLER_SUMMARY:\n",
    "    display_cols.append('handler_summary')\n",
    "if HAS_ACTIONS:\n",
    "    display_cols.append('operational_actions')\n",
    "if 'risk_level' in df.columns:\n",
    "    display_cols.append('risk_level')\n",
    "if HAS_ESCALATION:\n",
    "    display_cols.append('escalation_required')\n",
    "if 'escalation_flags' in df.columns:\n",
    "    display_cols.append('escalation_flags')\n",
    "\n",
    "# Sample diverse examples\n",
    "print(\"Sample Enriched Records for Handler Review:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Get one example per topic (up to 5)\n",
    "sample_df = df.groupby('topic').head(1).head(5)[display_cols]\n",
    "\n",
    "for _, row in sample_df.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Conversation ID: {row['conversation_id']}\")\n",
    "    print(f\"Topic: {row['topic']}\")\n",
    "    if HAS_HANDLER_SUMMARY:\n",
    "        print(f\"Summary: {row['handler_summary']}\")\n",
    "    if HAS_ACTIONS:\n",
    "        print(f\"Actions: {row['operational_actions']}\")\n",
    "    if 'risk_level' in df.columns:\n",
    "        print(f\"Risk: {row['risk_level']}\")\n",
    "    if HAS_ESCALATION:\n",
    "        esc = \"Yes\" if row['escalation_required'] else \"No\"\n",
    "        print(f\"Escalation: {esc}\")\n",
    "    if 'escalation_flags' in df.columns and row.get('escalation_flags'):\n",
    "        print(f\"Flags: {row['escalation_flags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Examples of conversations requiring escalation.\n",
    "\"\"\"\n",
    "if HAS_ESCALATION:\n",
    "    escalated = df[df['escalation_required'] == True]\n",
    "    \n",
    "    if len(escalated) > 0:\n",
    "        print(f\"Sample Escalated Conversations ({len(escalated)} total):\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        sample_escalated = escalated.head(3)\n",
    "        for _, row in sample_escalated.iterrows():\n",
    "            print(f\"\\n{'‚îÄ'*80}\")\n",
    "            print(f\"ID: {row['conversation_id']} | Topic: {row['topic']}\")\n",
    "            if 'risk_level' in df.columns:\n",
    "                print(f\"Risk Level: {row['risk_level']}\")\n",
    "            if 'escalation_flags' in df.columns:\n",
    "                print(f\"Flags: {row['escalation_flags']}\")\n",
    "            if HAS_HANDLER_SUMMARY:\n",
    "                print(f\"Summary: {row['handler_summary']}\")\n",
    "    else:\n",
    "        print(\"No escalated conversations found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dashboard-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Model Health Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "health-dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary dashboard of key model health and operational metrics.\n",
    "\"\"\"\n",
    "def get_status(value, good, warning, higher_is_better=True):\n",
    "    \"\"\"Return status emoji based on thresholds.\"\"\"\n",
    "    if higher_is_better:\n",
    "        return '‚úÖ' if value >= good else ('‚ö†Ô∏è' if value >= warning else '‚ùå')\n",
    "    else:\n",
    "        return '‚úÖ' if value <= good else ('‚ö†Ô∏è' if value <= warning else '‚ùå')\n",
    "\n",
    "# Calculate metrics\n",
    "high_conf_pct = (df['confidence'] == 'high').mean() * 100\n",
    "low_conf_pct = (df['confidence'] == 'low').mean() * 100\n",
    "error_pct = (df['topic'] == 'ERROR').mean() * 100\n",
    "general_pct = df['topic'].str.contains('General|Multi', case=False, na=False).mean() * 100\n",
    "\n",
    "dashboard_data = [\n",
    "    {'Metric': 'Total Conversations', 'Value': f\"{len(df):,}\", 'Status': '‚úÖ', 'Notes': 'Dataset size'},\n",
    "    {'Metric': 'Unique Topics', 'Value': f\"{df['topic'].nunique()}\", 'Status': '‚úÖ', 'Notes': 'Classification labels'},\n",
    "    {'Metric': 'High Confidence Rate', 'Value': f\"{high_conf_pct:.1f}%\", 'Status': get_status(high_conf_pct, 70, 50), 'Notes': 'Target: >70%'},\n",
    "    {'Metric': 'Low Confidence Rate', 'Value': f\"{low_conf_pct:.1f}%\", 'Status': get_status(low_conf_pct, 10, 20, False), 'Notes': 'Target: <10%'},\n",
    "    {'Metric': 'Error Rate', 'Value': f\"{error_pct:.1f}%\", 'Status': get_status(error_pct, 1, 5, False), 'Notes': 'API failures'},\n",
    "    {'Metric': 'Catch-All Rate', 'Value': f\"{general_pct:.1f}%\", 'Status': get_status(general_pct, 15, 25, False), 'Notes': 'Target: <20%'},\n",
    "]\n",
    "\n",
    "# Add operational metrics if available\n",
    "if HAS_ESCALATION:\n",
    "    esc_rate = df['escalation_required'].mean() * 100\n",
    "    dashboard_data.append({'Metric': 'Escalation Rate', 'Value': f\"{esc_rate:.1f}%\", 'Status': 'üìä', 'Notes': 'Requires human review'})\n",
    "\n",
    "if 'risk_level' in df.columns:\n",
    "    high_risk_pct = (df['risk_level'] == 'high').mean() * 100\n",
    "    dashboard_data.append({'Metric': 'High Risk Rate', 'Value': f\"{high_risk_pct:.1f}%\", 'Status': 'üìä', 'Notes': 'High-risk conversations'})\n",
    "\n",
    "if HAS_ACTIONS:\n",
    "    action_coverage = (df['num_actions'] > 0).mean() * 100\n",
    "    dashboard_data.append({'Metric': 'Action Coverage', 'Value': f\"{action_coverage:.1f}%\", 'Status': get_status(action_coverage, 80, 60), 'Notes': 'Has recommended actions'})\n",
    "\n",
    "dashboard = pd.DataFrame(dashboard_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä MODEL HEALTH DASHBOARD\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "print(dashboard.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taxonomy-goals-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Answers to Taxonomy Goals\n",
    "\n",
    "This section demonstrates how the classifier outputs support key business objectives:\n",
    "\n",
    "1. **Summarize main drivers of contact** - Understand why customers reach out\n",
    "2. **Escalate topics to the ops team** - Flag high-risk conversations for human review\n",
    "3. **Route to specialized AI workflows** - Direct conversations to appropriate handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "goal-1-drivers",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GOAL 1: Summarize the main drivers of contact\n",
    "\n",
    "The topic distribution provides a clear picture of why customers contact support.\n",
    "Combined with root cause analysis, we can identify systemic issues.\n",
    "\"\"\"\n",
    "print(\"=\"*80)\n",
    "print(\"TAXONOMY GOAL 1: Summarize Main Drivers of Contact\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä TOP CONTACT DRIVERS (by Topic):\")\n",
    "print(\"-\" * 60)\n",
    "for i, (topic, count) in enumerate(topic_counts.head(5).items(), 1):\n",
    "    pct = count / len(df) * 100\n",
    "    bar = '‚ñà' * int(pct/2)\n",
    "    print(f\"{i}. {topic}\")\n",
    "    print(f\"   {bar} {count} ({pct:.1f}%)\")\n",
    "\n",
    "if HAS_ROOT_CAUSE:\n",
    "    print(\"\\nüîç TOP ROOT CAUSES:\")\n",
    "    print(\"-\" * 60)\n",
    "    for cause, count in root_cause_counts.head(5).items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"   ‚Ä¢ {cause}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nüí° INSIGHT: These topic and root cause distributions enable:\")\n",
    "print(\"   - Weekly trend reporting on contact drivers\")\n",
    "print(\"   - Identification of systemic issues for proactive fixes\")\n",
    "print(\"   - Resource allocation based on topic volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "goal-2-escalation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GOAL 2: Escalate some topics to the ops team (e.g., Fraud)\n",
    "\n",
    "The escalation_required flag and escalation_flags enable automatic routing\n",
    "of high-risk conversations to human agents.\n",
    "\"\"\"\n",
    "print(\"=\"*80)\n",
    "print(\"TAXONOMY GOAL 2: Escalate High-Risk Topics to Ops Team\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if HAS_ESCALATION:\n",
    "    esc_total = df['escalation_required'].sum()\n",
    "    esc_rate = esc_total / len(df) * 100\n",
    "    \n",
    "    print(f\"\\nüö® ESCALATION SUMMARY:\")\n",
    "    print(f\"   Total escalations: {esc_total} out of {len(df)} ({esc_rate:.1f}%)\")\n",
    "    \n",
    "    if 'escalation_flags_list' in df.columns:\n",
    "        all_flags = [flag for flags in df['escalation_flags_list'] for flag in flags]\n",
    "        if all_flags:\n",
    "            flag_counts = pd.Series(all_flags).value_counts()\n",
    "            print(\"\\n‚ö†Ô∏è  ESCALATION TRIGGERS:\")\n",
    "            for flag, count in flag_counts.items():\n",
    "                print(f\"   ‚Ä¢ {flag}: {count}\")\n",
    "    \n",
    "    # Topics with highest escalation rates\n",
    "    print(\"\\nüìà TOPICS REQUIRING MOST ESCALATION:\")\n",
    "    esc_by_topic = df.groupby('topic')['escalation_required'].agg(['sum', 'mean'])\n",
    "    esc_by_topic['rate'] = (esc_by_topic['mean'] * 100).round(1)\n",
    "    esc_by_topic = esc_by_topic.sort_values('rate', ascending=False)\n",
    "    \n",
    "    for topic in esc_by_topic.head(3).index:\n",
    "        rate = esc_by_topic.loc[topic, 'rate']\n",
    "        count = int(esc_by_topic.loc[topic, 'sum'])\n",
    "        print(f\"   ‚Ä¢ {topic}: {rate}% escalation rate ({count} cases)\")\n",
    "    \n",
    "    print(\"\\nüí° INSIGHT: Escalation flags enable:\")\n",
    "    print(\"   - Automatic routing of fraud/abuse cases to specialized teams\")\n",
    "    print(\"   - Priority queuing for high-risk conversations\")\n",
    "    print(\"   - Real-time alerting for critical issues\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Escalation data not available in this dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "goal-3-routing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GOAL 3: Route conversations to different specialized AI workflows/agents\n",
    "\n",
    "Topic classification combined with operational_actions enables intelligent\n",
    "routing to specialized bots or human agents.\n",
    "\"\"\"\n",
    "print(\"=\"*80)\n",
    "print(\"TAXONOMY GOAL 3: Route to Specialized AI Workflows/Agents\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nü§ñ PROPOSED ROUTING RULES:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Topic':<45} {'Workflow':<25}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for topic in topic_counts.index:\n",
    "    workflow = routing_rules.get(topic, 'Unassigned')\n",
    "    count = topic_counts[topic]\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"{topic:<45} {workflow:<25} ({pct:.1f}%)\")\n",
    "\n",
    "if HAS_ACTIONS:\n",
    "    print(\"\\nüîß ACTION-BASED ROUTING INSIGHTS:\")\n",
    "    # Find which actions are most common for each potential workflow\n",
    "    \n",
    "    # Auth-related actions\n",
    "    auth_actions = ['reset_password_or_otp', 'resend_otp_or_verification', 'reactivate_account']\n",
    "    auth_count = sum(1 for actions in df['operational_actions_list'] for a in actions if a in auth_actions)\n",
    "    \n",
    "    # Order-related actions  \n",
    "    order_actions = ['check_order_status', 'provide_tracking_link_or_update', 'cancel_order']\n",
    "    order_count = sum(1 for actions in df['operational_actions_list'] for a in actions if a in order_actions)\n",
    "    \n",
    "    # Returns-related actions\n",
    "    returns_actions = ['initiate_return', 'initiate_refund', 'initiate_exchange_replacement']\n",
    "    returns_count = sum(1 for actions in df['operational_actions_list'] for a in actions if a in returns_actions)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Auth Support Bot: {auth_count} conversations with auth actions\")\n",
    "    print(f\"   ‚Ä¢ Order Management Bot: {order_count} conversations with order actions\")\n",
    "    print(f\"   ‚Ä¢ Returns Specialist: {returns_count} conversations with returns actions\")\n",
    "\n",
    "print(\"\\nüí° INSIGHT: Topic + action-based routing enables:\")\n",
    "print(\"   - First-contact resolution by specialized AI bots\")\n",
    "print(\"   - Reduced handling time through pre-filled action recommendations\")\n",
    "print(\"   - Seamless human handoff with full context when needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Final summary: How the enriched classifier outputs support business goals.\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìã SUMMARY: Classifier Outputs ‚Üí Business Value\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_table = \"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Output Field           ‚îÇ Business Application                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ topic                  ‚îÇ Primary routing, analytics, trend reporting        ‚îÇ\n",
    "‚îÇ confidence             ‚îÇ Quality monitoring, human review triggers          ‚îÇ\n",
    "‚îÇ handler_summary        ‚îÇ Agent briefing, quick context for handlers         ‚îÇ\n",
    "‚îÇ emotion                ‚îÇ Prioritization, tone adaptation for bots           ‚îÇ\n",
    "‚îÇ difficulty             ‚îÇ Workload balancing, SLA management                 ‚îÇ\n",
    "‚îÇ operational_actions    ‚îÇ Action suggestions, bot automation scripts         ‚îÇ\n",
    "‚îÇ risk_level             ‚îÇ Priority queuing, resource allocation              ‚îÇ\n",
    "‚îÇ escalation_required    ‚îÇ Automatic escalation to human agents               ‚îÇ\n",
    "‚îÇ escalation_flags       ‚îÇ Specialized team routing (fraud, legal, VIP)       ‚îÇ\n",
    "‚îÇ root_cause_code        ‚îÇ Systemic issue detection, product feedback         ‚îÇ\n",
    "‚îÇ root_cause_detail      ‚îÇ Specific issue context for resolution              ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\"\n",
    "print(summary_table)\n",
    "\n",
    "print(\"\\n‚úÖ The enriched classifier enables:\")\n",
    "print(\"   1. Data-driven understanding of contact drivers\")\n",
    "print(\"   2. Automatic escalation of high-risk conversations\")\n",
    "print(\"   3. Intelligent routing to specialized AI workflows\")\n",
    "print(\"   4. Actionable insights for handlers and operations teams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Analysis complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Review low-confidence samples for taxonomy refinement\")\n",
    "print(\"2. Validate escalation flags against actual outcomes\")\n",
    "print(\"3. Implement routing rules in production system\")\n",
    "print(\"4. Set up drift monitoring for topic/escalation rate shifts\")\n",
    "print(\"5. Build handler feedback loop for summary quality\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
